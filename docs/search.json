[
  {
    "objectID": "selected.html",
    "href": "selected.html",
    "title": "Selected Code",
    "section": "",
    "text": "Below are some examples of the work I‚Äôve done for the Long Term Ecological Research (LTER) Network synthesis working groups. I get to work on a variety of tasks as a data analyst for the LTER Network Office, which allows me to broaden my flexible skill set."
  },
  {
    "objectID": "selected.html#data-wrangling",
    "href": "selected.html#data-wrangling",
    "title": "Selected Code",
    "section": "Data Wrangling üõ†",
    "text": "Data Wrangling üõ†\nThe Plant Reproduction working group wanted plant trait data to research why some plants produce large amounts of seeds every few years. To assist this group, my team and I retrieved data from the TRY Plant Trait Database, which included traits such as plant seed mass, lifespan, flowering season, and seed persistence. Then we wrangled the TRY data so that we can combine it with a larger data set of plant traits that the working group already had. After much wrangling, we refined the integrated master data set to include 56 total variables for over 100 species. This data set was then used for further downstream analyses.\nLinks: GitHub repo"
  },
  {
    "objectID": "selected.html#exploratory-graphing",
    "href": "selected.html#exploratory-graphing",
    "title": "Selected Code",
    "section": "Exploratory Graphing üìà",
    "text": "Exploratory Graphing üìà\nThe Plant Reproduction working group requested me to help them explore a potential analysis for one of their manuscripts. They were interested in a time series plot showing the total seed mass production in grams per year at specific plots at a site. I manipulated the columns in the aforementioned integrated master data set to calculate the grams of seed per species per year. Then I graphed the time series, with a separate panel for each plot.\nLinks: GitHub repo"
  },
  {
    "objectID": "selected.html#spatial-data",
    "href": "selected.html#spatial-data",
    "title": "Selected Code",
    "section": "Spatial Data üåé",
    "text": "Spatial Data üåé\nThe Silica Export working group wanted to investigate drivers of riverine silicon exports and they requested for my team and I to identify and extract from various spatial data sets. In order to accomplish this, we first searched online for the data sets that best suited our needs. Then we gathered watershed shapefiles and extracted the spatial data within each watershed. Finally, we summarized the extracted values and exported them in a harmonized format that was easy to use for downstream analyses.\nLinks: GitHub repo"
  },
  {
    "objectID": "selected.html#text-mining",
    "href": "selected.html#text-mining",
    "title": "Selected Code",
    "section": "Text Mining üìë",
    "text": "Text Mining üìë\nThe Ecosystem Transitions working group needed to review over 3000 papers in order to prepare a meta-analysis on ecosystem transitions. They split the reading assignments between their group members, but to speed the process along, they requested for me to find a way to quickly decide whether a paper is worth reading or not.\nSo I created a script that filters and ranks the abstracts and titles based on positive and negative keywords. The more positive keywords an abstract and its associated title have, the more likely it was for the group to include the full paper in their meta-analysis. On the other hand, if a paper‚Äôs abstract/title has more negative keywords, it means that the group will probably not be interested in this paper.\nAfter discussing with the group, we decided that it would be helpful for the group members to see how many negative keywords were in each paper‚Äôs abstract and title. So I added a column to each person‚Äôs reading assignment list that shows the count of negative keywords for each abstract and title. That way, they could prioritize reading the abstracts that have the least negative keywords and save time by discarding the ones that have the most negative keywords.\nIn the end, the group was able to use my work to decide on the 700 or so papers that will be included in round 2 of the meta-analysis.\nLinks: GitHub repo"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "As part of the Long Term Ecological Research Network Office (LNO), I helped create some workshops in order to support our synthesis working groups. My colleagues and I have hosted these workshops numerous times on an as-needed basis for these groups."
  },
  {
    "objectID": "workshops.html#collaborative-coding-with-github",
    "href": "workshops.html#collaborative-coding-with-github",
    "title": "Workshops",
    "section": "Collaborative Coding with GitHub",
    "text": "Collaborative Coding with GitHub\n\nIn synthesis science, collaboration on code products is often integral to the productivity of the group. However, learning to use the software and graphical user interfaces that support this kind of teamwork can be a significant hurdle for teams that are already experts in their subject areas. This workshop is aimed at helping participants gain an understanding of the fundamental purpose and functioning of ‚Äúversion control‚Äù systems‚Äìspecifically GitHub‚Äìto help teams more effectively code collaboratively.\nLink: workshop website"
  },
  {
    "objectID": "workshops.html#coding-in-the-tidyverse",
    "href": "workshops.html#coding-in-the-tidyverse",
    "title": "Workshops",
    "section": "Coding in the tidyverse",
    "text": "Coding in the tidyverse\n\nFor teams that code using the R programming language, the most familiar tools are often part of ‚Äúbase R‚Äù meaning that those functions and packages come pre-loaded when R is installed. Relatively recently the tidyverse has emerged as a comprehensive suite of packages that can complement base R or serve as an alternative for some tasks. This includes packages like dplyr and tidyr as well as the perhaps infamous pipe operator (%>%) among many other tools. This workshop is aimed at helping participants use the tidyverse equivalents of fundamental data wrangling tasks that learners may be used to performing with base R.\nLink: workshop website"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Here are some projects I‚Äôve worked on as an undergrad in UC Santa Barbara!"
  },
  {
    "objectID": "projects.html#credit-card",
    "href": "projects.html#credit-card",
    "title": "Projects",
    "section": "Credit Card üí≥",
    "text": "Credit Card üí≥\nIn this project, I worked with my team to predict whether the client will default on credit card payments based on their gender, education, marital status, age, amount of the given credit, history of past payment, amount of bill statements and amount of previous payments.\nWe built the pipeline to preprocess the data and construct models. We applied several feature transformers such as VectorAssembler and StandardScaler from the PySpark ML package. The four models we developed were Logistic Regression, Decision Tree, Random Forest and Support Vector Machine. We evaluated our models‚Äô performance using the metrics derived from the confusion matrix, and then finally chose Support Vector Machine as our champion model because it has the best accuracy of 0.8065.\nLinks: project report and GitHub repo"
  },
  {
    "objectID": "projects.html#bees",
    "href": "projects.html#bees",
    "title": "Projects",
    "section": "Bees üêù",
    "text": "Bees üêù\nLarge, open-access biological datasets, like those hosted by Global Biotic Interactions (GloBI), have become increasingly accessible due to greater data collection, compilation, and storage. These databases serve to better inform our understanding of species occurrences, interactions, and ecosystem structure, broadly. In this work, we leverage GloBI data to better understand patterns of pollination, a biologically and economically essential biotic interaction between plants and pollinators. Specifically, we sought to develop a better understanding of bee specialization of pollen, an evolutionary trait in bees that underscores the stability and structure of pollinator interaction networks. We compared GloBI and expert-compiled data to better understand patterns in resource specialization. We then trained various machine learning models (Decision Trees, Support Vector Machine, Logistic Regression) to create a defining line between specialist and non-specialist bees. In addition, data transformation was also useful for more clearly differentiating our specialization groups.\nThrough our exploration of GloBI, we found several sources of bias, including the limitations of community data collection and scarcity of rare bees. We found a strong positive correlation between the number of sources (i.e.¬†literature, natural history collection) citing the interactions of a bee species and the number of plant families visited by that same bee species. We also found that while expert classification of bee specialists visit fewer plant families than other bees in the GloBI dataset, there are clusters of species that diverge from the expected trend. Our trained models suggested that binary classification was not completely effective in determining the label of ‚Äúspecialist‚Äù or ‚Äúnon-specialist‚Äù for all bee species. These findings indicate that observer bias, on a global scale, can skew our definition of resource specialization or generalization. Moreover, large, open-access datasets like GloBI can change our previous understanding of biological interactions and systems by accessing novel data sources and aggregation.\nLinks: project report and ESA 2021 meeting poster"
  },
  {
    "objectID": "projects.html#renewable-energy",
    "href": "projects.html#renewable-energy",
    "title": "Projects",
    "section": "Renewable Energy ‚òÄÔ∏è",
    "text": "Renewable Energy ‚òÄÔ∏è\nRenewable energy consumption has been increasing in the United States over the past 20 years as people sought alternatives to fossil fuels. Sources of renewable energy include hydroelectric power, geothermal, solar, wind, and biomass. In this project, I investigate the total monthly consumption of renewable energy in the United States from January 2001 to January 2020 and try to figure out a model that can be used to forecast how much renewable energy will be used in the future.\nIn order to achieve this goal, I used the Box-Jenkins methodology. This method involves data transformation, differencing, examining autocorrelation and partial autocorrelation functions, model parameter estimation, checking for stationarity and invertibility, and diagnostic checking. To summarize my results, I came up with three plausible models for the data, but ended up with two satisfactory models that passed all checking. I concluded that one model was better than the other because it had lower AICc, an information criterion, and used it to predict renewable energy consumption for February 2019 to January 2020. My predictions followed the actual data values well, meaning that my model can be used for future forecasting, and it also supports the conclusion that renewable energy consumption is on an upward trend.\nLinks: project report and GitHub repo"
  },
  {
    "objectID": "projects.html#spam-emails",
    "href": "projects.html#spam-emails",
    "title": "Projects",
    "section": "Spam Emails üìß",
    "text": "Spam Emails üìß\nCertain emails are automatically considered spam by algorithms in email systems. These algorithms track patterns of certain keywords, which allows them to classify spam and non-spam emails. This dataset, spambase.data, allows us to explore the connection between the frequency of keywords and whether an email is classified as spam. If such a connection exists, it would be more convenient for email users because their spam emails will be filtered out before reaching them.\nMy team‚Äôs question: Is there a relationship between the predictors (frequency of keywords/characters, length of sequences, number of capital letters) and whether an email is considered spam or not? If so, which predictors affect the response?\nLinks: project report and GitHub repo"
  },
  {
    "objectID": "projects.html#fossil-fuel",
    "href": "projects.html#fossil-fuel",
    "title": "Projects",
    "section": "Fossil Fuel ü¶ñ",
    "text": "Fossil Fuel ü¶ñ\nAs part of the UCSB Data Science Fellowship Tutoring Committee under Professor Yekaterina Kharitonova‚Äôs guidance, I created a lab project for undergrads in her Fall 2020 Introduction to Data Science 1 course. This lab project was made for the undergrads to practice their data analysis skills in Python. They were instructed to investigate how the COVID-19 lockdown affected monthly fossil fuel consumption in the United States from January 2001 to July 2020.\nLink: GitHub repo"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Angel Chen",
    "section": "",
    "text": "Hi, I‚Äôm Angel Chen! Welcome to my personal website ‚ú®\n\n \n  \n   \n  \n    \n     Email\n  \n  \n    \n     CV\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n\n\n\n\nEducation\n\n2021: Bachelor of Science in Statistics & Data Science | University of California, Santa Barbara\n\n\n\nExperience\n\n2022 - Present: Data Analyst | Long Term Ecological Research (LTER) Network\n2019 - 2022: Data Curator | Arctic Data Center (ADC)\n\n\n\nInterests\n\nOpen science\nReproducible workflows\nBirds\nFashion"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I‚Äôm a recent graduate from the University of California, Santa Barbara, with a Bachelor‚Äôs degree in Statistics & Data Science! My interests are open science and reproducible workflows!\nCurrently, I work as a data analyst at the National Center for Ecological Analysis and Synthesis (NCEAS), supporting the Long Term Ecological Research (LTER) Network synthesis working groups. I help the working groups develop reproducible workflows to wrangle, harmonize, analyze, and visualize ecological datasets. I also host workshops for them.\nBefore joining the LTER, I was a data curator for NCEAS Arctic Data Center. I created metadata records using Ecological Metadata Language (EML) and archived ecological datasets from research projects focused in the Arctic. Ensuring that the metadata is complete is a crucial part of making the data finable, accessible, interoperable, and reusable by others in the future.\nIn my spare time, I like to look at and admire birds. My favorite birds include rock doves and mourning doves. Here are some pictures I‚Äôve taken over the years:\n\n\n\n\nA pigeon flaps open its wings to balance itself on my hand, Golden Gate Park, San Francisco\n\n\n\n\n\nA pigeon grabs some millet from my hand, Golden Gate Park, San Francisco\n\n\n\n\n\nA crested duck looks closely at the ground, Golden Gate Park, San Francisco\n\n\n\n\n\nA female duck with its ducklings, Golden Gate Park, San Francisco\n\n\n\n\n\nA flock of pigeons gathers around a pile of rice, Chinatown, San Francisco\n\n\n\n\n\nA collared dove stops by my yard, San Francisco"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Conference presentations that I have participated in are listed here."
  },
  {
    "objectID": "presentations.html#section",
    "href": "presentations.html#section",
    "title": "Presentations",
    "section": "2022",
    "text": "2022\nLaMontagne, J. M., Crone, E. E., Redmond, M., Barton, J., Bell, D., Chaudhary, V. B., Chen, A., Cleavitt, N., Greene, D., Holland, E. P., Johnstone, J., Koenig, W., Lyon, N., Macias, D., Miller, T., Nigro, K., Pearse, I. S., Satake, A., Schulze, M., Slette, I., Snell, R., & Zimmerman, J. (2022, September 20). Cross-site synthesis: Patterns & drivers of plant reproduction across LTER sites. LTER All Scientists‚Äô Meeting, Pacific Grove, CA, United States.\nLink: poster"
  },
  {
    "objectID": "presentations.html#section-1",
    "href": "presentations.html#section-1",
    "title": "Presentations",
    "section": "2021",
    "text": "2021\nBachelder, N. R., Chen, A., Zoe, F., Rapaport, M. K., Bang, J., Solomon, S. J., Lee, M. J., & Seltmann, K. C. (2021, August 5). Leveraging Large Biological Interaction Data to Quantify Plant Specialization by Bees. Ecological Society of America Meeting, Virtual. Retrieved from https://escholarship.org/uc/item/33b2t2bq\nLink: poster"
  }
]